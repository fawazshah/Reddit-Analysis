{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_sentiment_reddit.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMftgcY9q7AY4B0wcDJdIkA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawazshah/Reddit-Analysis/blob/main/4_sentiment_vocab_overlap_reddit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moh_1_l1S5wb",
        "outputId": "9c953ac7-f34a-4744-86bc-314fc2d8187e"
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K-tm1qPRtJ2"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue_Be0bgRotx"
      },
      "source": [
        "submissions_lib_dem_con_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_liberal_democrats_conservative.tsv'\n",
        "submissions_lib_dem_con_df = pd.read_csv(submissions_lib_dem_con_url, sep='\\t')\n",
        "\n",
        "comments_lib_dem_con_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_liberal_democrats_conservative.tsv'\n",
        "comments_lib_dem_con_df = pd.read_csv(comments_lib_dem_con_url, sep='\\t')\n",
        "\n",
        "submissions_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_republican.tsv'\n",
        "submissions_rep_df = pd.read_csv(submissions_rep_url, sep='\\t')\n",
        "\n",
        "comments_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_republican.tsv'\n",
        "comments_rep_df = pd.read_csv(comments_rep_url, sep='\\t')\n",
        "\n",
        "submissions_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "submissions_ob_clin_sls_df = pd.read_csv(submissions_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "comments_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "comments_ob_clin_sls_df = pd.read_csv(comments_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "submissions_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_libertarian_sandersforpresident.tsv'\n",
        "submissions_libertarian_sfp_df = pd.read_csv(submissions_libertarian_sfp_url, sep='\\t')\n",
        "\n",
        "comments_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_libertarian_sandersforpresident.tsv'\n",
        "comments_libertarian_sfp_df = pd.read_csv(comments_libertarian_sfp_url, sep='\\t')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn-hh2zA3Zp9"
      },
      "source": [
        "submissions_df = pd.concat([submissions_lib_dem_con_df, submissions_rep_df, submissions_ob_clin_sls_df, submissions_libertarian_sfp_df], ignore_index=True)\n",
        "comments_df = pd.concat([comments_lib_dem_con_df, comments_rep_df, comments_ob_clin_sls_df, comments_libertarian_sfp_df], ignore_index=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWbo4L77TWtI",
        "outputId": "7e6f6314-0ce7-4423-dd7f-b0f94f7f7442"
      },
      "source": [
        "print(f\"No. submissions: {len(submissions_df)}\")\n",
        "print(f\"No. comments: {len(comments_df)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. submissions: 992\n",
            "No. comments: 50609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoPSpQi10wtD"
      },
      "source": [
        "### Data checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-mEhaxe0caL",
        "outputId": "97e0df3c-d46c-4cc9-8ba6-d22fee044a14"
      },
      "source": [
        "# Removing NAs\n",
        "\n",
        "print(submissions_df['article headline'].isna().sum())\n",
        "print(submissions_df['article body'].isna().sum())\n",
        "print(comments_df['comment body'].isna().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71r8x5LXUXM"
      },
      "source": [
        "comments_df.dropna(subset=['comment body'], inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuTtyXnzYTHJ",
        "outputId": "6433f6e0-10dc-4c19-d3fa-404dff456bf5"
      },
      "source": [
        "# Checking all submission ids in comments_df map to a submission in submissions_df\n",
        "\n",
        "submission_ids = list(submissions_df['submission id'])\n",
        "\n",
        "num_errors = 0\n",
        "for i, row in comments_df.iterrows():\n",
        "    if row['submission id'] not in submission_ids:\n",
        "        num_errors += 1\n",
        "print(f\"Num integrity errors: {num_errors}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num integrity errors: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v79DxtdVyInl"
      },
      "source": [
        "### Fixing left/right class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFVqBt8TyLbw",
        "outputId": "569385ce-bc9a-4135-d7b1-30d2fa76cc91"
      },
      "source": [
        "print(submissions_df['bias'].value_counts())\n",
        "print(comments_df['bias'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     600\n",
            "right    392\n",
            "Name: bias, dtype: int64\n",
            "right    44631\n",
            "left      5977\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8rH_to01Evn"
      },
      "source": [
        "Right is minority class in articles, however left is minority class in comments. We can't remove class imbalance independently in articles and in comments, since for any article we want to make sure all its comments are still in the comments dataset. Thus we fix class imbalance in comments by trimming all classes down to the size of the minority class, and then removing all articles whose comments are no longer present. Thus articles won't be exactly balanced.\n",
        "\n",
        "We tried other way around, but balancing articles causes comments to HEAVILY skew towards right (48,000 vs 2000 comments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVeXziWu3FMr",
        "outputId": "731cbe5c-93a4-44df-b35d-8bd488d0e9e9"
      },
      "source": [
        "comments_left_df = comments_df[comments_df['bias'] == 'left']\n",
        "comments_right_df = comments_df[comments_df['bias'] == 'right']\n",
        "\n",
        "# Undersample right class in comments to match left class\n",
        "\n",
        "left_count = len(comments_left_df)\n",
        "comments_right_under_df = comments_right_df.sample(left_count)\n",
        "\n",
        "comments_df = pd.concat([comments_left_df, comments_right_under_df], ignore_index=True)\n",
        "\n",
        "print(comments_df['bias'].value_counts())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     5977\n",
            "right    5977\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjbAuzo7WQDl"
      },
      "source": [
        "submissions_to_keep = Counter(set(comments_df['submission id']))\n",
        "all_submission_ids = Counter(list(submissions_df['submission id']))\n",
        "submissions_to_drop = all_submission_ids - submissions_to_keep\n",
        "\n",
        "indices_to_drop = submissions_df[submissions_df['submission id'].isin(submissions_to_drop)].index\n",
        "submissions_df.drop(indices_to_drop, inplace=True)\n",
        "submissions_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMjQe41IBRJd",
        "outputId": "ede038b3-75cf-48d3-c643-513875052a12"
      },
      "source": [
        "print(submissions_df['bias'].value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     419\n",
            "right    387\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cORaOacEEBQZ",
        "outputId": "ffa4f162-13ee-41fa-9f52-03a005278998"
      },
      "source": [
        "print(len(submissions_df))\n",
        "print(len(comments_df))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "806\n",
            "11954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv26S4SPH968"
      },
      "source": [
        "### See class distribution by subreddit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNOPBoYKIBv_",
        "outputId": "9bbca506-c5b4-4de9-e117-8db4af013c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "submissions_df['subreddit'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "liberal                255\n",
              "libertarian            189\n",
              "conservative           157\n",
              "hillaryclinton          59\n",
              "sandersforpresident     45\n",
              "republican              37\n",
              "obama                   33\n",
              "democrats               27\n",
              "shitliberalssay          4\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlP4t06uILjD",
        "outputId": "fa58d255-8230-4bdf-ac5b-18abb230cbec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "comments_df['subreddit'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "conservative           3202\n",
              "sandersforpresident    2765\n",
              "libertarian            2567\n",
              "liberal                2332\n",
              "democrats               646\n",
              "hillaryclinton          192\n",
              "republican              155\n",
              "shitliberalssay          53\n",
              "obama                    42\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obnFxRpRzlvW"
      },
      "source": [
        "### Simple text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apDuAD0hznjP"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # No lowercasing since upper-case words will indicate sentiment (anger or joy)\n",
        "    # Also no punctuation removal since ! and ? can indicate sentiment\n",
        "\n",
        "    # Whitespace removal\n",
        "    whitespace = '''\\n\\t'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in whitespace:\n",
        "            sentence = sentence.replace(ch, \" \")\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLThuJElzwyj"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "NWq4j_Wx0C2F",
        "outputId": "aa77f0f5-87f1-4d96-9dc9-dc18bba6a092"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Republicans now 'shocked, shocked' that there'...</td>\n",
              "      <td>© Greg Nash Republicans now 'shocked, shocked'...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Georgia certifies election results confirming ...</td>\n",
              "      <td>Georgia Secretary of State Ben Raffensperger h...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Report: QAnon Congresswoman Was Live-Tweeting ...</td>\n",
              "      <td>Domestic Terrorist: Rep. Lauren Boebert, a new...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>More than 175 current, former law enforcement ...</td>\n",
              "      <td>EXCLUSIVE: More than 175 current and former la...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>GOP group launches billboards demanding Cruz a...</td>\n",
              "      <td>GOP campaigners have called on senators Ted Cr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Study Shows 5.4 Million Have Lost Insurance Am...</td>\n",
              "      <td>Amid the worst public health crisis in a centu...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie — also known as Mr. The Struggle Continues</td>\n",
              "      <td>We use cookies on our websites for a number of...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Medicare for All backers won in safe Democrati...</td>\n",
              "      <td>The votes were still coming in when the Democr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie Sanders Says Country Must Get Ready for...</td>\n",
              "      <td>Bernie Sanders is sounding the alarm. The Verm...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie was one of only three Senators to vote ...</td>\n",
              "      <td>Last night an amendment to keep the U.S. embas...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>807 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    submission id  ...  bias\n",
              "0          l6a0q7  ...  left\n",
              "1          jxxs8b  ...  left\n",
              "2          kuscob  ...  left\n",
              "3          j2lufw  ...  left\n",
              "4          l8m3a8  ...  left\n",
              "..            ...  ...   ...\n",
              "802        hr3aiz  ...  left\n",
              "803        lz7cve  ...  left\n",
              "804        jvx3os  ...  left\n",
              "805        indmby  ...  left\n",
              "806        le1obs  ...  left\n",
              "\n",
              "[807 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "is04mZWN0Dh4",
        "outputId": "50d46bfd-ae3b-4874-da96-5df05daf7b72"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Hey Republican geniuses, I'll bet you were als...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The deficit exploded after the republican tax ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The Republican Party is a fucking cancer on ou...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>I wish I had gold to give you, just for the ti...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>it's not these politicians that really bug me,...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11949</th>\n",
              "      <td>gaf13kw</td>\n",
              "      <td>jjq9wt</td>\n",
              "      <td>conservative</td>\n",
              "      <td>I think we should keep in mind that people are...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>gc5quz1</td>\n",
              "      <td>jtfocr</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>I know I will probably regret engaging with yo...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>g6wfmjx</td>\n",
              "      <td>j0za59</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>Oh so *NOW* people care about our bloated tax ...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11952</th>\n",
              "      <td>girswja</td>\n",
              "      <td>kucm6n</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>Who got beat to death during the BLM protests?</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11953</th>\n",
              "      <td>g4abttl</td>\n",
              "      <td>invfxf</td>\n",
              "      <td>conservative</td>\n",
              "      <td>Smoking that good ol /r/politics</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11954 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      comment id  ...   bias\n",
              "0        gkzccbm  ...   left\n",
              "1        gkzg91o  ...   left\n",
              "2        gkzfown  ...   left\n",
              "3        gkz73xz  ...   left\n",
              "4        gkzhm11  ...   left\n",
              "...          ...  ...    ...\n",
              "11949    gaf13kw  ...  right\n",
              "11950    gc5quz1  ...  right\n",
              "11951    g6wfmjx  ...  right\n",
              "11952    girswja  ...  right\n",
              "11953    g4abttl  ...  right\n",
              "\n",
              "[11954 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIKNDOw1z1dh"
      },
      "source": [
        "### Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdUAW0kN9jFi"
      },
      "source": [
        "subreddits = [\n",
        "    'liberal',\n",
        "    'democrats',\n",
        "    'conservative',\n",
        "    'republican',\n",
        "    'obama',\n",
        "    'hillaryclinton',\n",
        "    'shitliberalssay',\n",
        "    'libertarian',\n",
        "    'sandersforpresident'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5MaUvzq9ud_"
      },
      "source": [
        "# We will store only the compound (overall) sentiment\n",
        "\n",
        "results = {}\n",
        "\n",
        "for subreddit in subreddits:\n",
        "    results[subreddit] = {}\n",
        "    results[subreddit]['article headlines'] = []\n",
        "    results[subreddit]['article bodies'] = []\n",
        "    results[subreddit]['comment bodies'] = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZmHQjnXNwwH"
      },
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    headline = row['article headline']\n",
        "    body = row['article body']\n",
        "    results[subreddit]['article headlines'].append(sia.polarity_scores(headline)['compound'])\n",
        "    results[subreddit]['article bodies'].append(sia.polarity_scores(body)['compound'])\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    comment = row['comment body']\n",
        "    results[subreddit]['comment bodies'].append(sia.polarity_scores(comment)['compound'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGTvQnyb_QAP",
        "outputId": "543d85b6-4f8e-4d8d-a1ed-d3b0c9c5aa2a"
      },
      "source": [
        "for subreddit in subreddits:\n",
        "    print(subreddit)\n",
        "    headline_sentiments = results[subreddit]['article headlines']\n",
        "    article_body_sentiments = results[subreddit]['article bodies']\n",
        "    comment_sentiments = results[subreddit]['comment bodies']\n",
        "    print(f\"Headline sentiment: {sum(headline_sentiments) / len(headline_sentiments)}\")\n",
        "    print(f\"Article body sentiment: {sum(article_body_sentiments) / len(article_body_sentiments)}\")\n",
        "    print(f\"Comment sentiment: {sum(comment_sentiments) / len(comment_sentiments)}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liberal\n",
            "Headline sentiment: -0.12600352941176465\n",
            "Article body sentiment: -0.04648666666666667\n",
            "Comment sentiment: -0.06488906518010307\n",
            "\n",
            "democrats\n",
            "Headline sentiment: -0.12061851851851853\n",
            "Article body sentiment: 0.3994111111111111\n",
            "Comment sentiment: 0.03578343653250772\n",
            "\n",
            "conservative\n",
            "Headline sentiment: -0.06153121019108282\n",
            "Article body sentiment: -0.011707643312101897\n",
            "Comment sentiment: 0.03333940886699502\n",
            "\n",
            "republican\n",
            "Headline sentiment: -0.004027027027027033\n",
            "Article body sentiment: 0.1531054054054054\n",
            "Comment sentiment: -0.01843708609271523\n",
            "\n",
            "obama\n",
            "Headline sentiment: 0.060933333333333325\n",
            "Article body sentiment: 0.4760060606060606\n",
            "Comment sentiment: 0.2396809523809524\n",
            "\n",
            "hillaryclinton\n",
            "Headline sentiment: -0.0037677966101694943\n",
            "Article body sentiment: 0.5367000000000001\n",
            "Comment sentiment: 0.036123958333333324\n",
            "\n",
            "shitliberalssay\n",
            "Headline sentiment: -0.41447500000000004\n",
            "Article body sentiment: -0.33492500000000003\n",
            "Comment sentiment: 0.14244864864864865\n",
            "\n",
            "libertarian\n",
            "Headline sentiment: -0.09687157894736843\n",
            "Article body sentiment: -0.03523842105263156\n",
            "Comment sentiment: -0.07045895316804396\n",
            "\n",
            "sandersforpresident\n",
            "Headline sentiment: 0.050557777777777764\n",
            "Article body sentiment: 0.2410622222222222\n",
            "Comment sentiment: 0.08994886075949364\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yCY8lX1NrGy"
      },
      "source": [
        "### Further preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUm1l8L6R2o_"
      },
      "source": [
        "Now we perform further text preprocessing before vocab analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5igJsQRz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea56ad1-ecae-446a-de08-16d8b4c0d938"
      },
      "source": [
        "# Text preprocessing preparation\n",
        "\n",
        "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:          \n",
        "        return None\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# required for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# required for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zeni9Z_1NwbL"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Punctuation removal - leaving in full stops, exclamation marks and question marks\n",
        "    punctuations = '''()-—[]{};:'\"“”‘’\\,<>/@#$%^&*_~'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in punctuations: \n",
        "            sentence = sentence.replace(ch, \"\")\n",
        "\n",
        "    # Stop word removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    remaining_words = [word for word in sentence.split() if not word in stop_words]\n",
        "\n",
        "    sentence = \" \".join(remaining_words)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_words = []\n",
        "\n",
        "    # In order to lemmatise we must first POS-tag each sentence\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    for word, tag in tagged:\n",
        "        pos = nltk_tag_to_wordnet_tag(tag) \n",
        "        if pos is not None:\n",
        "            word = lemmatizer.lemmatize(word, pos=pos)\n",
        "\n",
        "        lemmatized_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(lemmatized_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avRNm30BS7eM"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie9DK4mvgvob"
      },
      "source": [
        "# One-hot encode labels\n",
        "# left == 0\n",
        "# right == 1\n",
        "\n",
        "def encode_labels(label):\n",
        "    if label == \"left\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "submissions_df['bias'] = submissions_df['bias'].apply(encode_labels)\n",
        "comments_df['bias'] = comments_df['bias'].apply(encode_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu2eTdaSTFHt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "67dc7e01-930d-43cc-c03b-cc32561e2949"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican shock shocked there deficit hahahah...</td>\n",
              "      <td>© greg nash republican shock shocked there def...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>georgia certifies election result confirm bide...</td>\n",
              "      <td>georgia secretary state ben raffensperger hold...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>report qanon congresswoman livetweeting nancy ...</td>\n",
              "      <td>domestic terrorist rep. lauren boebert newly e...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>175 current former law enforcement official en...</td>\n",
              "      <td>exclusive 175 current former law enforcement o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>gop group launch billboard demand cruz hawley ...</td>\n",
              "      <td>gop campaigner call senator ted cruz josh hawl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>study show 5.4 million lose insurance amid pan...</td>\n",
              "      <td>amid bad public health crisis century devastat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie also know mr. struggle continue</td>\n",
              "      <td>use cooky websites number purpose include anal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>medicare backer safe democratic district trump...</td>\n",
              "      <td>vote still come democratic establishment set n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie sander say country must get ready trump...</td>\n",
              "      <td>bernie sander sound alarm . vermont senator wa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie one three senator vote keep u.s. embass...</td>\n",
              "      <td>last night amendment keep u.s. embassy jerusal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>807 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    submission id  ... bias\n",
              "0          l6a0q7  ...    0\n",
              "1          jxxs8b  ...    0\n",
              "2          kuscob  ...    0\n",
              "3          j2lufw  ...    0\n",
              "4          l8m3a8  ...    0\n",
              "..            ...  ...  ...\n",
              "802        hr3aiz  ...    0\n",
              "803        lz7cve  ...    0\n",
              "804        jvx3os  ...    0\n",
              "805        indmby  ...    0\n",
              "806        le1obs  ...    0\n",
              "\n",
              "[807 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhz2MTlDTHNV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "193fea1d-2bd5-4dc7-bdcd-ce21d589182b"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>hey republican genius ill bet also unaware tru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>deficit explode republican tax cut . single on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican party fuck cancer country . need fi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>wish gold give title alone .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>politician really bug reaction predictable . f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11949</th>\n",
              "      <td>gaf13kw</td>\n",
              "      <td>jjq9wt</td>\n",
              "      <td>conservative</td>\n",
              "      <td>think keep mind people arent vote joe biden . ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>gc5quz1</td>\n",
              "      <td>jtfocr</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>know probably regret engage you . personal lib...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>g6wfmjx</td>\n",
              "      <td>j0za59</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>oh people care bloated tax code .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11952</th>\n",
              "      <td>girswja</td>\n",
              "      <td>kucm6n</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>get beat death blm protest ?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11953</th>\n",
              "      <td>g4abttl</td>\n",
              "      <td>invfxf</td>\n",
              "      <td>conservative</td>\n",
              "      <td>smoke good ol rpolitics</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11954 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      comment id  ... bias\n",
              "0        gkzccbm  ...    0\n",
              "1        gkzg91o  ...    0\n",
              "2        gkzfown  ...    0\n",
              "3        gkz73xz  ...    0\n",
              "4        gkzhm11  ...    0\n",
              "...          ...  ...  ...\n",
              "11949    gaf13kw  ...    1\n",
              "11950    gc5quz1  ...    1\n",
              "11951    g6wfmjx  ...    1\n",
              "11952    girswja  ...    1\n",
              "11953    g4abttl  ...    1\n",
              "\n",
              "[11954 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69bpyemGvVoT"
      },
      "source": [
        "### Remove empty comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa1PFiSNvdm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccdfcdaf-1a10-4889-b06f-66c33f695a71"
      },
      "source": [
        "empty_comments = comments_df[comments_df['comment body'] == ''].index\n",
        "print(len(empty_comments))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJQImPRzodw"
      },
      "source": [
        "comments_df.drop(empty_comments, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXujLRcM_3W"
      },
      "source": [
        "### Vocab overlap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xDSDEBNAt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b47239-a05b-460b-efd4-ed3700bf8805"
      },
      "source": [
        "article_headline_vocab = []\n",
        "article_body_vocab = []\n",
        "comment_vocab = []\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    article_headline = row['article headline']\n",
        "    article_body = row['article body']\n",
        "    for word in article_headline.split():\n",
        "        article_headline_vocab.append(word)\n",
        "    for word in article_body.split():\n",
        "        article_body_vocab.append(word)\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    comment_body = row['comment body']\n",
        "    for word in comment_body.split():\n",
        "        comment_vocab.append(word)\n",
        "\n",
        "print(len(article_headline_vocab))\n",
        "print(len(article_body_vocab))\n",
        "print(len(comment_vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9263\n",
            "298624\n",
            "245732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYTHcILBNmdr"
      },
      "source": [
        "article_headline_multiset = Counter(article_headline_vocab)\n",
        "article_body_multiset = Counter(article_body_vocab)\n",
        "comment_multiset = Counter(comment_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AINbnyPRe3rQ",
        "outputId": "950175ca-aa92-438c-b206-6721ed2371eb"
      },
      "source": [
        "# Computing Jaccard distances\n",
        "\n",
        "headline_body_intersect = list((article_headline_multiset & article_body_multiset).elements())\n",
        "headline_comment_intersect = list((article_headline_multiset & comment_multiset).elements())\n",
        "body_comment_intersect = list((article_body_multiset & comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_intersect))\n",
        "print(len(headline_comment_intersect))\n",
        "print(len(body_comment_intersect))\n",
        "\n",
        "headline_body_union = list((article_headline_multiset | article_body_multiset).elements())\n",
        "headline_comment_union = list((article_headline_multiset | comment_multiset).elements())\n",
        "body_comment_union = list((article_body_multiset | comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_union))\n",
        "print(len(headline_comment_union))\n",
        "print(len(body_comment_union))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9038\n",
            "8755\n",
            "167584\n",
            "298849\n",
            "246240\n",
            "376772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zahTnTbIfeiQ",
        "outputId": "9a357831-b70f-440b-93df-bb3b8118884f"
      },
      "source": [
        "headline_body_jaccard = len(headline_body_intersect) / len(headline_body_union)\n",
        "headline_comment_jaccard = len(headline_comment_intersect) / len(headline_comment_union)\n",
        "body_comment_jaccard = len(body_comment_intersect) / len(body_comment_union)\n",
        "\n",
        "print(f\"Headline & article body Jaccard distance: {headline_body_jaccard}\")\n",
        "print(f\"Headline and comment body Jaccard distance: {headline_comment_jaccard}\")\n",
        "print(f\"Article body and comment body Jaccard distance: {body_comment_jaccard}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headline & article body Jaccard distance: 0.030242697817292344\n",
            "Headline and comment body Jaccard distance: 0.03555474333983106\n",
            "Article body and comment body Jaccard distance: 0.4447888908942278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fSOH0Z40SHv"
      },
      "source": [
        "### Save data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDT0SflI0TIS"
      },
      "source": [
        "submissions_df.to_csv('submissions_preprocessed.tsv', sep='\\t', index=False)\n",
        "comments_df.to_csv('comments_preprocessed.tsv', sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mEp3mi2mnBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}