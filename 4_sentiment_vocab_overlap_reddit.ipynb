{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_sentiment_reddit.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCFDTjqj1E5eYt4TcRhCTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawazshah/Reddit-Analysis/blob/main/4_sentiment_vocab_overlap_reddit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moh_1_l1S5wb",
        "outputId": "796b011c-3541-4124-d863-bd6133b18325"
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K-tm1qPRtJ2"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue_Be0bgRotx"
      },
      "source": [
        "submissions_lib_dem_con_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_liberal_democrats_conservative.tsv'\n",
        "submissions_lib_dem_con_df = pd.read_csv(submissions_lib_dem_con_url, sep='\\t')\n",
        "\n",
        "comments_lib_dem_con_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_liberal_democrats_conservative.tsv'\n",
        "comments_lib_dem_con_df = pd.read_csv(comments_lib_dem_con_url, sep='\\t')\n",
        "\n",
        "submissions_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_republican.tsv'\n",
        "submissions_rep_df = pd.read_csv(submissions_rep_url, sep='\\t')\n",
        "\n",
        "comments_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_republican.tsv'\n",
        "comments_rep_df = pd.read_csv(comments_rep_url, sep='\\t')\n",
        "\n",
        "submissions_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "submissions_ob_clin_sls_df = pd.read_csv(submissions_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "comments_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "comments_ob_clin_sls_df = pd.read_csv(comments_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "submissions_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_libertarian_sandersforpresident.tsv'\n",
        "submissions_libertarian_sfp_df = pd.read_csv(submissions_libertarian_sfp_url, sep='\\t')\n",
        "\n",
        "comments_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_libertarian_sandersforpresident.tsv'\n",
        "comments_libertarian_sfp_df = pd.read_csv(comments_libertarian_sfp_url, sep='\\t')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn-hh2zA3Zp9"
      },
      "source": [
        "submissions_df = pd.concat([submissions_lib_dem_con_df, submissions_rep_df, submissions_ob_clin_sls_df, submissions_libertarian_sfp_df], ignore_index=True)\n",
        "comments_df = pd.concat([comments_lib_dem_con_df, comments_rep_df, comments_ob_clin_sls_df, comments_libertarian_sfp_df], ignore_index=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWbo4L77TWtI",
        "outputId": "e605f68c-699b-4b32-d4bb-5541f8075ad2"
      },
      "source": [
        "print(f\"No. submissions: {len(submissions_df)}\")\n",
        "print(f\"No. comments: {len(comments_df)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. submissions: 992\n",
            "No. comments: 50609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoPSpQi10wtD"
      },
      "source": [
        "### Data checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-mEhaxe0caL",
        "outputId": "a9de6245-6222-4867-b58b-eaef7b9aa5d6"
      },
      "source": [
        "# Removing NAs\n",
        "\n",
        "print(submissions_df['article headline'].isna().sum())\n",
        "print(submissions_df['article body'].isna().sum())\n",
        "print(comments_df['comment body'].isna().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71r8x5LXUXM"
      },
      "source": [
        "comments_df.dropna(subset=['comment body'], inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuTtyXnzYTHJ",
        "outputId": "c32e3bf3-87dc-4c13-9ee4-ce549fa9f2b6"
      },
      "source": [
        "# Checking all submission ids in comments_df map to a submission in submissions_df\n",
        "\n",
        "submission_ids = list(submissions_df['submission id'])\n",
        "\n",
        "num_errors = 0\n",
        "for i, row in comments_df.iterrows():\n",
        "    if row['submission id'] not in submission_ids:\n",
        "        num_errors += 1\n",
        "print(f\"Num integrity errors: {num_errors}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num integrity errors: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v79DxtdVyInl"
      },
      "source": [
        "### Fixing left/right class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFVqBt8TyLbw",
        "outputId": "cad6288c-3cce-47bf-cf99-c630eebf38ca"
      },
      "source": [
        "print(submissions_df['bias'].value_counts())\n",
        "print(comments_df['bias'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     600\n",
            "right    392\n",
            "Name: bias, dtype: int64\n",
            "right    44631\n",
            "left      5977\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8rH_to01Evn"
      },
      "source": [
        "Right is minority class in articles, however left is minority class in comments. We can't remove class imbalance independently in articles and in comments, since for any article we want to make sure all its comments are still in the comments dataset. Thus we fix class imbalance in comments by trimming all classes down to the size of the minority class, and then removing all articles whose comments are no longer present. Thus articles won't be exactly balanced.\n",
        "\n",
        "We tried other way around, but balancing articles causes comments to HEAVILY skew towards right (48,000 vs 2000 comments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVeXziWu3FMr",
        "outputId": "13125530-17cb-4dd0-9ab2-7eeb6b5a01ed"
      },
      "source": [
        "comments_left_df = comments_df[comments_df['bias'] == 'left']\n",
        "comments_right_df = comments_df[comments_df['bias'] == 'right']\n",
        "\n",
        "# Undersample right class in comments to match left class\n",
        "\n",
        "left_count = len(comments_left_df)\n",
        "comments_right_under_df = comments_right_df.sample(left_count)\n",
        "\n",
        "comments_df = pd.concat([comments_left_df, comments_right_under_df], ignore_index=True)\n",
        "\n",
        "print(comments_df['bias'].value_counts())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     5977\n",
            "right    5977\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjbAuzo7WQDl"
      },
      "source": [
        "submissions_to_keep = Counter(set(comments_df['submission id']))\n",
        "all_submission_ids = Counter(list(submissions_df['submission id']))\n",
        "submissions_to_drop = all_submission_ids - submissions_to_keep\n",
        "\n",
        "indices_to_drop = submissions_df[submissions_df['submission id'].isin(submissions_to_drop)].index\n",
        "submissions_df.drop(indices_to_drop, inplace=True)\n",
        "submissions_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMjQe41IBRJd",
        "outputId": "8e7b3a11-1cef-463f-ef3a-e4447d02910d"
      },
      "source": [
        "print(submissions_df['bias'].value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     419\n",
            "right    387\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cORaOacEEBQZ",
        "outputId": "af3c2538-1a4a-4b55-8aa1-da00906fe77a"
      },
      "source": [
        "print(len(submissions_df))\n",
        "print(len(comments_df))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "806\n",
            "11954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obnFxRpRzlvW"
      },
      "source": [
        "### Simple text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apDuAD0hznjP"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # No lowercasing since upper-case words will indicate sentiment (anger or joy)\n",
        "    # Also no punctuation removal since ! and ? can indicate sentiment\n",
        "\n",
        "    # Whitespace removal\n",
        "    whitespace = '''\\n\\t'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in whitespace:\n",
        "            sentence = sentence.replace(ch, \" \")\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLThuJElzwyj"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "NWq4j_Wx0C2F",
        "outputId": "32fb5ed5-c84f-443e-e43b-19d033bb7a30"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Republicans now 'shocked, shocked' that there'...</td>\n",
              "      <td>© Greg Nash Republicans now 'shocked, shocked'...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Georgia certifies election results confirming ...</td>\n",
              "      <td>Georgia Secretary of State Ben Raffensperger h...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Report: QAnon Congresswoman Was Live-Tweeting ...</td>\n",
              "      <td>Domestic Terrorist: Rep. Lauren Boebert, a new...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>More than 175 current, former law enforcement ...</td>\n",
              "      <td>EXCLUSIVE: More than 175 current and former la...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>GOP group launches billboards demanding Cruz a...</td>\n",
              "      <td>GOP campaigners have called on senators Ted Cr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Study Shows 5.4 Million Have Lost Insurance Am...</td>\n",
              "      <td>Amid the worst public health crisis in a centu...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie — also known as Mr. The Struggle Continues</td>\n",
              "      <td>We use cookies on our websites for a number of...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Medicare for All backers won in safe Democrati...</td>\n",
              "      <td>The votes were still coming in when the Democr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie Sanders Says Country Must Get Ready for...</td>\n",
              "      <td>Bernie Sanders is sounding the alarm. The Verm...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie was one of only three Senators to vote ...</td>\n",
              "      <td>Last night an amendment to keep the U.S. embas...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>806 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    submission id  ...  bias\n",
              "0          l6a0q7  ...  left\n",
              "1          jxxs8b  ...  left\n",
              "2          kuscob  ...  left\n",
              "3          j2lufw  ...  left\n",
              "4          l8m3a8  ...  left\n",
              "..            ...  ...   ...\n",
              "801        hr3aiz  ...  left\n",
              "802        lz7cve  ...  left\n",
              "803        jvx3os  ...  left\n",
              "804        indmby  ...  left\n",
              "805        le1obs  ...  left\n",
              "\n",
              "[806 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "is04mZWN0Dh4",
        "outputId": "d95a0d6e-327c-4a03-f94a-30c90600ecf5"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Hey Republican geniuses, I'll bet you were als...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The deficit exploded after the republican tax ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The Republican Party is a fucking cancer on ou...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>I wish I had gold to give you, just for the ti...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>it's not these politicians that really bug me,...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11949</th>\n",
              "      <td>galze45</td>\n",
              "      <td>jkuqjq</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>Produce the tape. The internet has many copies...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>gvtbfig</td>\n",
              "      <td>my5wni</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>I’d rather see fed legalization too with this ...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>gj68for</td>\n",
              "      <td>kwqevc</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>How does it feel to be objectively *that* wron...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11952</th>\n",
              "      <td>ginmbaz</td>\n",
              "      <td>ktge5g</td>\n",
              "      <td>conservative</td>\n",
              "      <td>Back to land lines and radio I guess...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11953</th>\n",
              "      <td>gjyxljp</td>\n",
              "      <td>l1dlf1</td>\n",
              "      <td>conservative</td>\n",
              "      <td>Literally the same can be said of Trump suppor...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11954 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      comment id  ...   bias\n",
              "0        gkzccbm  ...   left\n",
              "1        gkzg91o  ...   left\n",
              "2        gkzfown  ...   left\n",
              "3        gkz73xz  ...   left\n",
              "4        gkzhm11  ...   left\n",
              "...          ...  ...    ...\n",
              "11949    galze45  ...  right\n",
              "11950    gvtbfig  ...  right\n",
              "11951    gj68for  ...  right\n",
              "11952    ginmbaz  ...  right\n",
              "11953    gjyxljp  ...  right\n",
              "\n",
              "[11954 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIKNDOw1z1dh"
      },
      "source": [
        "### Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdUAW0kN9jFi"
      },
      "source": [
        "subreddits = [\n",
        "    'liberal',\n",
        "    'democrats',\n",
        "    'conservative',\n",
        "    'republican',\n",
        "    'obama',\n",
        "    'hillaryclinton',\n",
        "    'shitliberalssay',\n",
        "    'libertarian',\n",
        "    'sandersforpresident'\n",
        "]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5MaUvzq9ud_"
      },
      "source": [
        "# We will store only the compound (overall) sentiment\n",
        "\n",
        "results = {}\n",
        "\n",
        "for subreddit in subreddits:\n",
        "    results[subreddit] = {}\n",
        "    results[subreddit]['article headlines'] = []\n",
        "    results[subreddit]['article bodies'] = []\n",
        "    results[subreddit]['comment bodies'] = []"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZmHQjnXNwwH"
      },
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    headline = row['article headline']\n",
        "    body = row['article body']\n",
        "    results[subreddit]['article headlines'].append(sia.polarity_scores(headline)['compound'])\n",
        "    results[subreddit]['article bodies'].append(sia.polarity_scores(body)['compound'])\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    comment = row['comment body']\n",
        "    results[subreddit]['comment bodies'].append(sia.polarity_scores(comment)['compound'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGTvQnyb_QAP",
        "outputId": "7ef76440-2df5-4ae9-df54-071763195ffe"
      },
      "source": [
        "for subreddit in subreddits:\n",
        "    print(subreddit)\n",
        "    headline_sentiments = results[subreddit]['article headlines']\n",
        "    article_body_sentiments = results[subreddit]['article bodies']\n",
        "    comment_sentiments = results[subreddit]['comment bodies']\n",
        "    print(f\"Headline sentiment: {sum(headline_sentiments) / len(headline_sentiments)}\")\n",
        "    print(f\"Article body sentiment: {sum(article_body_sentiments) / len(article_body_sentiments)}\")\n",
        "    print(f\"Comment sentiment: {sum(comment_sentiments) / len(comment_sentiments)}\")\n",
        "    print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liberal\n",
            "Headline sentiment: -0.12600352941176465\n",
            "Article body sentiment: -0.04648666666666667\n",
            "Comment sentiment: -0.06488906518010307\n",
            "\n",
            "democrats\n",
            "Headline sentiment: -0.12061851851851853\n",
            "Article body sentiment: 0.3994111111111111\n",
            "Comment sentiment: 0.03578343653250772\n",
            "\n",
            "conservative\n",
            "Headline sentiment: -0.06153121019108282\n",
            "Article body sentiment: -0.011707643312101897\n",
            "Comment sentiment: 0.019313163547100318\n",
            "\n",
            "republican\n",
            "Headline sentiment: 0.012752777777777771\n",
            "Article body sentiment: 0.17397222222222222\n",
            "Comment sentiment: 0.018928571428571423\n",
            "\n",
            "obama\n",
            "Headline sentiment: 0.060933333333333325\n",
            "Article body sentiment: 0.4760060606060606\n",
            "Comment sentiment: 0.2396809523809524\n",
            "\n",
            "hillaryclinton\n",
            "Headline sentiment: -0.0037677966101694943\n",
            "Article body sentiment: 0.5367000000000001\n",
            "Comment sentiment: 0.036123958333333324\n",
            "\n",
            "shitliberalssay\n",
            "Headline sentiment: -0.41447500000000004\n",
            "Article body sentiment: -0.33492500000000003\n",
            "Comment sentiment: -0.036435897435897445\n",
            "\n",
            "libertarian\n",
            "Headline sentiment: -0.09687157894736843\n",
            "Article body sentiment: -0.03523842105263156\n",
            "Comment sentiment: -0.052041975308641936\n",
            "\n",
            "sandersforpresident\n",
            "Headline sentiment: 0.050557777777777764\n",
            "Article body sentiment: 0.2410622222222222\n",
            "Comment sentiment: 0.08994886075949364\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yCY8lX1NrGy"
      },
      "source": [
        "### Further preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUm1l8L6R2o_"
      },
      "source": [
        "Now we perform further text preprocessing before vocab analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5igJsQRz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7205b93c-ff3c-4f64-b69f-010a8da4ef87"
      },
      "source": [
        "# Text preprocessing preparation\n",
        "\n",
        "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:          \n",
        "        return None\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# required for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# required for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zeni9Z_1NwbL"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Punctuation removal\n",
        "    punctuations = '''!()-—[]{};:'\"“”‘’\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in punctuations: \n",
        "            sentence = sentence.replace(ch, \"\")\n",
        "\n",
        "    # Stop word removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    remaining_words = [word for word in sentence.split() if not word in stop_words]\n",
        "\n",
        "    sentence = \" \".join(remaining_words)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_words = []\n",
        "\n",
        "    # In order to lemmatise we must first POS-tag each sentence\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    for word, tag in tagged:\n",
        "        pos = nltk_tag_to_wordnet_tag(tag) \n",
        "        if pos is not None:\n",
        "            word = lemmatizer.lemmatize(word, pos=pos)\n",
        "\n",
        "        lemmatized_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(lemmatized_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avRNm30BS7eM"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie9DK4mvgvob"
      },
      "source": [
        "# One-hot encode labels\n",
        "# left == 0\n",
        "# right == 1\n",
        "\n",
        "def encode_labels(label):\n",
        "    if label == \"left\":\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "submissions_df['bias'] = submissions_df['bias'].apply(encode_labels)\n",
        "comments_df['bias'] = comments_df['bias'].apply(encode_labels)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu2eTdaSTFHt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e513be7e-aa01-4608-9b44-3d76132b3163"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican shock shocked there deficit hahahah...</td>\n",
              "      <td>© greg nash republican shock shocked there def...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>georgia certifies election result confirm bide...</td>\n",
              "      <td>georgia secretary state ben raffensperger hold...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>report qanon congresswoman livetweeting nancy ...</td>\n",
              "      <td>domestic terrorist rep lauren boebert newly el...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>175 current former law enforcement official en...</td>\n",
              "      <td>exclusive 175 current former law enforcement o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>gop group launch billboard demand cruz hawley ...</td>\n",
              "      <td>gop campaigner call senator ted cruz josh hawl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>study show 54 million lose insurance amid pand...</td>\n",
              "      <td>amid bad public health crisis century devastat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie also know mr struggle continue</td>\n",
              "      <td>use cooky websites number purpose include anal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>medicare backer safe democratic district trump...</td>\n",
              "      <td>vote still come democratic establishment set n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie sander say country must get ready trump...</td>\n",
              "      <td>bernie sander sound alarm vermont senator warn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie one three senator vote keep us embassy ...</td>\n",
              "      <td>last night amendment keep us embassy jerusalem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>806 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    submission id  ... bias\n",
              "0          l6a0q7  ...    0\n",
              "1          jxxs8b  ...    0\n",
              "2          kuscob  ...    0\n",
              "3          j2lufw  ...    0\n",
              "4          l8m3a8  ...    0\n",
              "..            ...  ...  ...\n",
              "801        hr3aiz  ...    0\n",
              "802        lz7cve  ...    0\n",
              "803        jvx3os  ...    0\n",
              "804        indmby  ...    0\n",
              "805        le1obs  ...    0\n",
              "\n",
              "[806 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhz2MTlDTHNV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c79c1c63-e960-465b-ea87-edc1f67edeb4"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>hey republican genius ill bet also unaware tru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>deficit explode republican tax cut single one ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican party fuck cancer country need finish</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>wish gold give title alone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>politician really bug reaction predictable foo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11949</th>\n",
              "      <td>galze45</td>\n",
              "      <td>jkuqjq</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>produce tape internet many copy video show cop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>gvtbfig</td>\n",
              "      <td>my5wni</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>id rather see fed legalization clause maybe li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>gj68for</td>\n",
              "      <td>kwqevc</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>feel objectively wrong youre show everyone und...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11952</th>\n",
              "      <td>ginmbaz</td>\n",
              "      <td>ktge5g</td>\n",
              "      <td>conservative</td>\n",
              "      <td>back land line radio guess</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11953</th>\n",
              "      <td>gjyxljp</td>\n",
              "      <td>l1dlf1</td>\n",
              "      <td>conservative</td>\n",
              "      <td>literally say trump supporter antifa boogeyman...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11954 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      comment id  ... bias\n",
              "0        gkzccbm  ...    0\n",
              "1        gkzg91o  ...    0\n",
              "2        gkzfown  ...    0\n",
              "3        gkz73xz  ...    0\n",
              "4        gkzhm11  ...    0\n",
              "...          ...  ...  ...\n",
              "11949    galze45  ...    1\n",
              "11950    gvtbfig  ...    1\n",
              "11951    gj68for  ...    1\n",
              "11952    ginmbaz  ...    1\n",
              "11953    gjyxljp  ...    1\n",
              "\n",
              "[11954 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69bpyemGvVoT"
      },
      "source": [
        "### Remove empty comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa1PFiSNvdm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbb5bb7-407e-45ba-ac1b-09f1d2bb836f"
      },
      "source": [
        "empty_comments = comments_df[comments_df['comment body'] == ''].index\n",
        "print(len(empty_comments))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJQImPRzodw"
      },
      "source": [
        "comments_df.drop(empty_comments, inplace=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXujLRcM_3W"
      },
      "source": [
        "### Vocab overlap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xDSDEBNAt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc028f8a-cf82-4cd1-b754-12deb7e2c5ab"
      },
      "source": [
        "article_headline_vocab = []\n",
        "article_body_vocab = []\n",
        "comment_vocab = []\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    article_headline = row['article headline']\n",
        "    article_body = row['article body']\n",
        "    for word in article_headline.split():\n",
        "        article_headline_vocab.append(word)\n",
        "    for word in article_body.split():\n",
        "        article_body_vocab.append(word)\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    comment_body = row['comment body']\n",
        "    for word in comment_body.split():\n",
        "        comment_vocab.append(word)\n",
        "\n",
        "print(len(article_headline_vocab))\n",
        "print(len(article_body_vocab))\n",
        "print(len(comment_vocab))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8814\n",
            "275713\n",
            "213610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYTHcILBNmdr"
      },
      "source": [
        "article_headline_multiset = Counter(article_headline_vocab)\n",
        "article_body_multiset = Counter(article_body_vocab)\n",
        "comment_multiset = Counter(comment_vocab)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AINbnyPRe3rQ",
        "outputId": "ecee06ab-951a-40ca-d628-ed37ae0752a4"
      },
      "source": [
        "# Computing Jaccard distances\n",
        "\n",
        "headline_body_intersect = list((article_headline_multiset & article_body_multiset).elements())\n",
        "headline_comment_intersect = list((article_headline_multiset & comment_multiset).elements())\n",
        "body_comment_intersect = list((article_body_multiset & comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_intersect))\n",
        "print(len(headline_comment_intersect))\n",
        "print(len(body_comment_intersect))\n",
        "\n",
        "headline_body_union = list((article_headline_multiset | article_body_multiset).elements())\n",
        "headline_comment_union = list((article_headline_multiset | comment_multiset).elements())\n",
        "body_comment_union = list((article_body_multiset | comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_union))\n",
        "print(len(headline_comment_union))\n",
        "print(len(body_comment_union))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8597\n",
            "8319\n",
            "145517\n",
            "275930\n",
            "214105\n",
            "343806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zahTnTbIfeiQ",
        "outputId": "e3314c54-659a-4ddb-f02b-e5638b19fffc"
      },
      "source": [
        "headline_body_jaccard = len(headline_body_intersect) / len(headline_body_union)\n",
        "headline_comment_jaccard = len(headline_comment_intersect) / len(headline_comment_union)\n",
        "body_comment_jaccard = len(body_comment_intersect) / len(body_comment_union)\n",
        "\n",
        "print(f\"Headline & article body Jaccard distance: {headline_body_jaccard}\")\n",
        "print(f\"Headline and comment body Jaccard distance: {headline_comment_jaccard}\")\n",
        "print(f\"Article body and comment body Jaccard distance: {body_comment_jaccard}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headline & article body Jaccard distance: 0.031156452723516834\n",
            "Headline and comment body Jaccard distance: 0.03885476752060905\n",
            "Article body and comment body Jaccard distance: 0.423253230019255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fSOH0Z40SHv"
      },
      "source": [
        "### Save data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDT0SflI0TIS"
      },
      "source": [
        "submissions_df.to_csv('submissions_preprocessed.tsv', sep='\\t', index=False)\n",
        "comments_df.to_csv('comments_preprocessed.tsv', sep='\\t', index=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mEp3mi2mnBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}