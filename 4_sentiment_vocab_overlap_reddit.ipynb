{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_sentiment_reddit.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPT5TsJAi1yO9nPAq7yOR87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawazshah/Reddit-Analysis/blob/main/4_sentiment_vocab_overlap_reddit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moh_1_l1S5wb",
        "outputId": "5792e69a-bac0-4750-911a-aca6ca6a7912"
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K-tm1qPRtJ2"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue_Be0bgRotx"
      },
      "source": [
        "submissions_lib_dem_con_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_liberal_democrats_conservative_republicans.tsv'\n",
        "submissions_lib_dem_con_rep_df = pd.read_csv(submissions_lib_dem_con_rep_url, sep='\\t')\n",
        "\n",
        "comments_lib_dem_con_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_liberal_democrats_conservative_republicans.tsv'\n",
        "comments_lib_dem_con_rep_df = pd.read_csv(comments_lib_dem_con_rep_url, sep='\\t')\n",
        "\n",
        "submissions_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "submissions_ob_clin_sls_df = pd.read_csv(submissions_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "comments_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "comments_ob_clin_sls_df = pd.read_csv(comments_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "submissions_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_libertarian_sandersforpresident.tsv'\n",
        "submissions_libertarian_sfp_df = pd.read_csv(submissions_libertarian_sfp_url, sep='\\t')\n",
        "\n",
        "comments_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_libertarian_sandersforpresident.tsv'\n",
        "comments_libertarian_sfp_df = pd.read_csv(comments_libertarian_sfp_url, sep='\\t')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn-hh2zA3Zp9"
      },
      "source": [
        "submissions_df = pd.concat([submissions_lib_dem_con_rep_df, submissions_ob_clin_sls_df, submissions_libertarian_sfp_df], ignore_index=True)\n",
        "comments_df = pd.concat([comments_lib_dem_con_rep_df, comments_ob_clin_sls_df, comments_libertarian_sfp_df], ignore_index=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoPSpQi10wtD"
      },
      "source": [
        "### Data checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-mEhaxe0caL",
        "outputId": "1f2ffe8a-ef4e-4c6f-84ed-ccec08597c4b"
      },
      "source": [
        "print(submissions_df['article headline'].isna().sum())\n",
        "print(submissions_df['article body'].isna().sum())\n",
        "print(comments_df['comment body'].isna().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71r8x5LXUXM"
      },
      "source": [
        "comments_df.dropna(subset=['comment body'], inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obnFxRpRzlvW"
      },
      "source": [
        "### Simple text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apDuAD0hznjP"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # No lowercasing since upper-case words will indicate sentiment (anger or joy)\n",
        "    # Also no punctuation removal since ! and ? can indicate sentiment\n",
        "\n",
        "    # Whitespace removal\n",
        "    whitespace = '''\\n\\t'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in whitespace:\n",
        "            sentence = sentence.replace(ch, \" \")\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLThuJElzwyj"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "NWq4j_Wx0C2F",
        "outputId": "e8aa4f94-6513-4183-c13b-81c34ac4e986"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Republicans now 'shocked, shocked' that there'...</td>\n",
              "      <td>Â© Greg Nash Republicans now 'shocked, shocked'...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Georgia certifies election results confirming ...</td>\n",
              "      <td>Georgia Secretary of State Ben Raffensperger h...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Report: QAnon Congresswoman Was Live-Tweeting ...</td>\n",
              "      <td>Domestic Terrorist: Rep. Lauren Boebert, a new...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>More than 175 current, former law enforcement ...</td>\n",
              "      <td>EXCLUSIVE: More than 175 current and former la...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>GOP group launches billboards demanding Cruz a...</td>\n",
              "      <td>GOP campaigners have called on senators Ted Cr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Study Shows 5.4 Million Have Lost Insurance Am...</td>\n",
              "      <td>Amid the worst public health crisis in a centu...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie â also known as Mr. The Struggle Continues</td>\n",
              "      <td>We use cookies on our websites for a number of...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Medicare for All backers won in safe Democrati...</td>\n",
              "      <td>The votes were still coming in when the Democr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie Sanders Says Country Must Get Ready for...</td>\n",
              "      <td>Bernie Sanders is sounding the alarm. The Verm...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1038</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie was one of only three Senators to vote ...</td>\n",
              "      <td>Last night an amendment to keep the U.S. embas...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1039 rows Ã 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     submission id  ...  bias\n",
              "0           l6a0q7  ...  left\n",
              "1           jxxs8b  ...  left\n",
              "2           kuscob  ...  left\n",
              "3           j2lufw  ...  left\n",
              "4           l8m3a8  ...  left\n",
              "...            ...  ...   ...\n",
              "1034        hr3aiz  ...  left\n",
              "1035        lz7cve  ...  left\n",
              "1036        jvx3os  ...  left\n",
              "1037        indmby  ...  left\n",
              "1038        le1obs  ...  left\n",
              "\n",
              "[1039 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "is04mZWN0Dh4",
        "outputId": "eb1628d8-959c-4703-ca99-df63eb89b97e"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Hey Republican geniuses, I'll bet you were als...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The deficit exploded after the republican tax ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The Republican Party is a fucking cancer on ou...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>I wish I had gold to give you, just for the ti...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>it's not these politicians that really bug me,...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101969</th>\n",
              "      <td>gt8z5yp</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Non-AMP Link: [Thereâs a bunch of recent artic...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101970</th>\n",
              "      <td>gt9e1a4</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>The companies that donât pay taxes (like Amazo...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101971</th>\n",
              "      <td>gt9fypm</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>âPay taxes through stocksâ is so vague as to b...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101972</th>\n",
              "      <td>gt9s4nv</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>No, he didnât make $23B in profit. The value o...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101973</th>\n",
              "      <td>gt9w9jp</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>You also donât lose until you sell. At least t...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101973 rows Ã 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       comment id  ...  bias\n",
              "0         gkzccbm  ...  left\n",
              "1         gkzg91o  ...  left\n",
              "2         gkzfown  ...  left\n",
              "3         gkz73xz  ...  left\n",
              "4         gkzhm11  ...  left\n",
              "...           ...  ...   ...\n",
              "101969    gt8z5yp  ...  left\n",
              "101970    gt9e1a4  ...  left\n",
              "101971    gt9fypm  ...  left\n",
              "101972    gt9s4nv  ...  left\n",
              "101973    gt9w9jp  ...  left\n",
              "\n",
              "[101973 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIKNDOw1z1dh"
      },
      "source": [
        "### Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdUAW0kN9jFi"
      },
      "source": [
        "subreddits = [\n",
        "    'liberal',\n",
        "    'democrats',\n",
        "    'conservative',\n",
        "    'republicans',\n",
        "    'obama',\n",
        "    'hillaryclinton',\n",
        "    'shitliberalssay',\n",
        "    'libertarian',\n",
        "    'sandersforpresident'\n",
        "]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5MaUvzq9ud_"
      },
      "source": [
        "# We will store only the compound (overall) sentiment\n",
        "\n",
        "results = {}\n",
        "\n",
        "for subreddit in subreddits:\n",
        "    results[subreddit] = {}\n",
        "    results[subreddit]['article headlines'] = []\n",
        "    results[subreddit]['article bodies'] = []\n",
        "    results[subreddit]['comment bodies'] = []"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZmHQjnXNwwH"
      },
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    headline = row['article headline']\n",
        "    body = row['article body']\n",
        "    results[subreddit]['article headlines'].append(sia.polarity_scores(headline)['compound'])\n",
        "    results[subreddit]['article bodies'].append(sia.polarity_scores(body)['compound'])\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    comment = row['comment body']\n",
        "    results[subreddit]['comment bodies'].append(sia.polarity_scores(comment)['compound'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGTvQnyb_QAP",
        "outputId": "89cec6f6-ed95-4f37-93b6-69acf8213b8d"
      },
      "source": [
        "for subreddit in subreddits:\n",
        "    print(subreddit)\n",
        "    headline_sentiments = results[subreddit]['article headlines']\n",
        "    article_body_sentiments = results[subreddit]['article bodies']\n",
        "    comment_sentiments = results[subreddit]['comment bodies']\n",
        "    print(f\"Headline sentiment: {sum(headline_sentiments) / len(headline_sentiments)}\")\n",
        "    print(f\"Article body sentiment: {sum(article_body_sentiments) / len(article_body_sentiments)}\")\n",
        "    print(f\"Comment sentiment: {sum(comment_sentiments) / len(comment_sentiments)}\")\n",
        "    print()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liberal\n",
            "Headline sentiment: -0.127591472868217\n",
            "Article body sentiment: -0.02572480620155042\n",
            "Comment sentiment: -0.06145019904458616\n",
            "\n",
            "democrats\n",
            "Headline sentiment: -0.16293103448275864\n",
            "Article body sentiment: 0.38970689655172425\n",
            "Comment sentiment: 0.03598296022201663\n",
            "\n",
            "conservative\n",
            "Headline sentiment: -0.05971562500000001\n",
            "Article body sentiment: -4.374999999996743e-06\n",
            "Comment sentiment: 0.019022813248099398\n",
            "\n",
            "republicans\n",
            "Headline sentiment: -0.02522911392405063\n",
            "Article body sentiment: 0.1171746835443038\n",
            "Comment sentiment: -0.06247160493827159\n",
            "\n",
            "obama\n",
            "Headline sentiment: 0.10161307692307692\n",
            "Article body sentiment: 0.5443384615384614\n",
            "Comment sentiment: 0.30162500000000014\n",
            "\n",
            "hillaryclinton\n",
            "Headline sentiment: 0.03828181818181818\n",
            "Article body sentiment: 0.5253062937062937\n",
            "Comment sentiment: 0.0345304347826087\n",
            "\n",
            "shitliberalssay\n",
            "Headline sentiment: -0.41447500000000004\n",
            "Article body sentiment: -0.33492500000000003\n",
            "Comment sentiment: -0.015377812853373501\n",
            "\n",
            "libertarian\n",
            "Headline sentiment: -0.096634554973822\n",
            "Article body sentiment: -0.032361256544502566\n",
            "Comment sentiment: -0.05258004820699454\n",
            "\n",
            "sandersforpresident\n",
            "Headline sentiment: 0.050557777777777764\n",
            "Article body sentiment: 0.2352311111111111\n",
            "Comment sentiment: 0.061219410160734664\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yCY8lX1NrGy"
      },
      "source": [
        "### Further preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUm1l8L6R2o_"
      },
      "source": [
        "Now we perform further text preprocessing before vocab analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5igJsQRz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81532671-ec4e-463c-b52b-3660cc77f51d"
      },
      "source": [
        "# Text preprocessing preparation\n",
        "\n",
        "stop_words = [\"the\", \"a\", \"an\", \"as\", \"this\", \"that\", \"is\", \"and\", \"or\", \"on\",\n",
        "              \"at\", \"to\", \"in\", \"by\", \"than\", \"of\", \"for\", \"be\", \"i\", \"you\", \n",
        "              \"he\", \"she\", \"his\", \"her\", \"do\", \"it\", \"with\"]\n",
        "\n",
        "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:          \n",
        "        return None\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# required for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# required for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zeni9Z_1NwbL"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Punctuation removal\n",
        "    punctuations = '''!()-â[]{};:'\"ââââ\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in punctuations: \n",
        "            sentence = sentence.replace(ch, \"\")\n",
        "\n",
        "    # Stop word removal\n",
        "    remaining_words = []\n",
        "    \n",
        "    for word in sentence.split():\n",
        "        if word not in stop_words:\n",
        "            remaining_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(remaining_words)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_words = []\n",
        "\n",
        "    # In order to lemmatise we must first POS-tag each sentence\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    for word, tag in tagged:\n",
        "        pos = nltk_tag_to_wordnet_tag(tag) \n",
        "        if pos is not None:\n",
        "            word = lemmatizer.lemmatize(word, pos=pos)\n",
        "\n",
        "        lemmatized_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(lemmatized_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avRNm30BS7eM"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu2eTdaSTFHt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "89f9de45-0c97-43a4-f75f-2caaa9fdcb09"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican now shock shocked there deficit hah...</td>\n",
              "      <td>Â© greg nash republican now shock shocked there...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>georgia certifies election result confirm bide...</td>\n",
              "      <td>georgia secretary state ben raffensperger hold...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>report qanon congresswoman be livetweeting nan...</td>\n",
              "      <td>domestic terrorist rep lauren boebert newly el...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>more 175 current former law enforcement offici...</td>\n",
              "      <td>exclusive more 175 current former law enforcem...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>gop group launch billboard demand cruz hawley ...</td>\n",
              "      <td>gop campaigner have call senator ted cruz josh...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>study show 54 million have lose insurance amid...</td>\n",
              "      <td>amid bad public health crisis century devastat...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie also know mr struggle continue</td>\n",
              "      <td>we use cooky our website number purpose includ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>medicare all backer win safe democratic distri...</td>\n",
              "      <td>vote be still come when democratic establishme...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie sander say country must get ready trump...</td>\n",
              "      <td>bernie sander sound alarm vermont senator warn...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1038</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie be one only three senator vote against ...</td>\n",
              "      <td>last night amendment keep us embassy jerusalem...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1039 rows Ã 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     submission id  ...  bias\n",
              "0           l6a0q7  ...  left\n",
              "1           jxxs8b  ...  left\n",
              "2           kuscob  ...  left\n",
              "3           j2lufw  ...  left\n",
              "4           l8m3a8  ...  left\n",
              "...            ...  ...   ...\n",
              "1034        hr3aiz  ...  left\n",
              "1035        lz7cve  ...  left\n",
              "1036        jvx3os  ...  left\n",
              "1037        indmby  ...  left\n",
              "1038        le1obs  ...  left\n",
              "\n",
              "[1039 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhz2MTlDTHNV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1f9dd6fb-e511-4fdf-a62c-49f125b37ee8"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>hey republican genius ill bet be also unaware ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>deficit explode after republican tax cut not s...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican party fuck cancer our country they ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>wish have gold give just title alone</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>its not these politician really bug me their r...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101969</th>\n",
              "      <td>gt8z5yp</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>nonamp link there bunch recent article out the...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101970</th>\n",
              "      <td>gt9e1a4</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>company dont pay tax like amazon nike obvious ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101971</th>\n",
              "      <td>gt9fypm</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>pay tax through stock so vague meaningless hed...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101972</th>\n",
              "      <td>gt9s4nv</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>no didnt make 23b profit value share increase ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101973</th>\n",
              "      <td>gt9w9jp</td>\n",
              "      <td>mj44yw</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>also dont lose until sell least thats what tel...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101973 rows Ã 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       comment id  ...  bias\n",
              "0         gkzccbm  ...  left\n",
              "1         gkzg91o  ...  left\n",
              "2         gkzfown  ...  left\n",
              "3         gkz73xz  ...  left\n",
              "4         gkzhm11  ...  left\n",
              "...           ...  ...   ...\n",
              "101969    gt8z5yp  ...  left\n",
              "101970    gt9e1a4  ...  left\n",
              "101971    gt9fypm  ...  left\n",
              "101972    gt9s4nv  ...  left\n",
              "101973    gt9w9jp  ...  left\n",
              "\n",
              "[101973 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXujLRcM_3W"
      },
      "source": [
        "###Â Vocab overlap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xDSDEBNAt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbec6493-9708-4ea0-d1d6-796d94f1fbcd"
      },
      "source": [
        "article_headline_vocab = []\n",
        "article_body_vocab = []\n",
        "comment_vocab = []\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    article_headline = row['article headline']\n",
        "    article_body = row['article body']\n",
        "    for word in article_headline.split():\n",
        "        article_headline_vocab.append(word)\n",
        "    for word in article_body.split():\n",
        "        article_body_vocab.append(word)\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    comment_body = row['comment body']\n",
        "    for word in comment_body.split():\n",
        "        comment_vocab.append(word)\n",
        "\n",
        "print(len(article_headline_vocab))\n",
        "print(len(article_body_vocab))\n",
        "print(len(comment_vocab))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13062\n",
            "418125\n",
            "2345412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYTHcILBNmdr"
      },
      "source": [
        "article_headline_multiset = Counter(article_headline_vocab)\n",
        "article_body_multiset = Counter(article_body_vocab)\n",
        "comment_multiset = Counter(comment_vocab)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AINbnyPRe3rQ",
        "outputId": "b0a24b78-2531-4916-b1d8-cf74985788f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Computing Jaccard distances\n",
        "\n",
        "headline_body_intersect = list((article_headline_multiset & article_body_multiset).elements())\n",
        "headline_comment_intersect = list((article_headline_multiset & comment_multiset).elements())\n",
        "body_comment_intersect = list((article_body_multiset & comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_intersect))\n",
        "print(len(headline_comment_intersect))\n",
        "print(len(body_comment_intersect))\n",
        "\n",
        "headline_body_union = list((article_headline_multiset | article_body_multiset).elements())\n",
        "headline_comment_union = list((article_headline_multiset | comment_multiset).elements())\n",
        "body_comment_union = list((article_body_multiset | comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_union))\n",
        "print(len(headline_comment_union))\n",
        "print(len(body_comment_union))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12775\n",
            "12804\n",
            "386738\n",
            "418412\n",
            "2345670\n",
            "2376799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zahTnTbIfeiQ",
        "outputId": "46b7bc5e-82fc-45d5-8483-7cd0ea3a5c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "headline_body_jaccard = len(headline_body_intersect) / len(headline_body_union)\n",
        "headline_comment_jaccard = len(headline_comment_intersect) / len(headline_comment_union)\n",
        "body_comment_jaccard = len(body_comment_intersect) / len(body_comment_union)\n",
        "\n",
        "print(headline_body_jaccard)\n",
        "print(headline_comment_jaccard)\n",
        "print(body_comment_jaccard)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.030532107109738728\n",
            "0.005458568340815204\n",
            "0.1627138012091052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7rpzfpkhx_M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}