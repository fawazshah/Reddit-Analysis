{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_sentiment_reddit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNakyAl9Xl+lbi7d13hpzcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawazshah/Reddit-Analysis/blob/main/4_sentiment_vocab_overlap_reddit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moh_1_l1S5wb",
        "outputId": "3f5ff6bb-d52a-47d8-da60-03ff0d3c3ce3"
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K-tm1qPRtJ2"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue_Be0bgRotx"
      },
      "source": [
        "submissions_lib_dem_con_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_liberal_democrats_conservative.tsv'\n",
        "submissions_lib_dem_con_df = pd.read_csv(submissions_lib_dem_con_url, sep='\\t')\n",
        "\n",
        "comments_lib_dem_con_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_liberal_democrats_conservative.tsv'\n",
        "comments_lib_dem_con_df = pd.read_csv(comments_lib_dem_con_url, sep='\\t')\n",
        "\n",
        "submissions_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_republican.tsv'\n",
        "submissions_rep_df = pd.read_csv(submissions_rep_url, sep='\\t')\n",
        "\n",
        "comments_rep_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_republican.tsv'\n",
        "comments_rep_df = pd.read_csv(comments_rep_url, sep='\\t')\n",
        "\n",
        "submissions_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "submissions_ob_clin_sls_df = pd.read_csv(submissions_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "comments_ob_clin_sls_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_obama_hillaryclinton_shitliberalssay.tsv'\n",
        "comments_ob_clin_sls_df = pd.read_csv(comments_ob_clin_sls_url, sep='\\t')\n",
        "\n",
        "submissions_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/submissions_top300_year_libertarian_sandersforpresident.tsv'\n",
        "submissions_libertarian_sfp_df = pd.read_csv(submissions_libertarian_sfp_url, sep='\\t')\n",
        "\n",
        "comments_libertarian_sfp_url = 'https://raw.githubusercontent.com/fawazshah/Reddit-Analysis/master/data/assembled-data/comments_top300_year_libertarian_sandersforpresident.tsv'\n",
        "comments_libertarian_sfp_df = pd.read_csv(comments_libertarian_sfp_url, sep='\\t')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn-hh2zA3Zp9"
      },
      "source": [
        "submissions_df = pd.concat([submissions_lib_dem_con_df, submissions_rep_df, submissions_ob_clin_sls_df, submissions_libertarian_sfp_df], ignore_index=True)\n",
        "comments_df = pd.concat([comments_lib_dem_con_df, comments_rep_df, comments_ob_clin_sls_df, comments_libertarian_sfp_df], ignore_index=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWbo4L77TWtI",
        "outputId": "db304f61-7898-4620-bfd7-615b71ceae20"
      },
      "source": [
        "print(f\"No. submissions: {len(submissions_df)}\")\n",
        "print(f\"No. comments: {len(comments_df)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. submissions: 992\n",
            "No. comments: 50609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoPSpQi10wtD"
      },
      "source": [
        "### Data checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-mEhaxe0caL",
        "outputId": "086dc760-a3b4-43b9-c2ce-30af36898531"
      },
      "source": [
        "print(submissions_df['article headline'].isna().sum())\n",
        "print(submissions_df['article body'].isna().sum())\n",
        "print(comments_df['comment body'].isna().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71r8x5LXUXM"
      },
      "source": [
        "comments_df.dropna(subset=['comment body'], inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuTtyXnzYTHJ",
        "outputId": "8ec6a9c9-d827-43ce-cbd7-48467a553581"
      },
      "source": [
        "submission_ids = list(submissions_df['submission id'])\n",
        "\n",
        "num_errors = 0\n",
        "for i, row in comments_df.iterrows():\n",
        "    if row['submission id'] not in submission_ids:\n",
        "        num_errors += 1\n",
        "print(f\"Num integrity errors: {num_errors}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num integrity errors: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v79DxtdVyInl"
      },
      "source": [
        "### Fixing left/right class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFVqBt8TyLbw",
        "outputId": "868ace59-457d-4ef3-cfae-d10a56ad8bd7"
      },
      "source": [
        "print(submissions_df['bias'].value_counts())\n",
        "print(comments_df['bias'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     600\n",
            "right    392\n",
            "Name: bias, dtype: int64\n",
            "right    44631\n",
            "left      5977\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8rH_to01Evn"
      },
      "source": [
        "Right is minority class in articles, however left is minority class in comments. We can't remove class imbalance independently in articles and in comments, since for any article we want to make sure all its comments are still in the comments dataset. Thus we fix class imbalance in comments by trimming all classes down to the size of the minority class, and then removing all articles whose comments are no longer present. Thus articles won't be exactly balanced.\n",
        "\n",
        "We tried other way around, but balancing articles causes comments to HEAVILY skew towards right (48,000 vs 2000 comments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVeXziWu3FMr",
        "outputId": "fa214e2f-c94b-4b14-9ed7-903a206aa3a3"
      },
      "source": [
        "comments_left_df = comments_df[comments_df['bias'] == 'left']\n",
        "comments_right_df = comments_df[comments_df['bias'] == 'right']\n",
        "\n",
        "# Undersample right class in comments to match left class\n",
        "\n",
        "left_count = len(comments_left_df)\n",
        "comments_right_under_df = comments_right_df.sample(left_count)\n",
        "\n",
        "comments_df = pd.concat([comments_left_df, comments_right_under_df], ignore_index=True)\n",
        "\n",
        "print(comments_df['bias'].value_counts())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "right    5977\n",
            "left     5977\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjbAuzo7WQDl"
      },
      "source": [
        "submissions_to_keep = Counter(set(comments_df['submission id']))\n",
        "all_submission_ids = Counter(list(submissions_df['submission id']))\n",
        "submissions_to_drop = all_submission_ids - submissions_to_keep\n",
        "\n",
        "indices_to_drop = submissions_df[submissions_df['submission id'].isin(submissions_to_drop)].index\n",
        "submissions_df.drop(indices_to_drop, inplace=True)\n",
        "submissions_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMjQe41IBRJd",
        "outputId": "37da179d-84c6-4a91-87f0-e3b7c6f925e7"
      },
      "source": [
        "print(submissions_df['bias'].value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "left     419\n",
            "right    388\n",
            "Name: bias, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cORaOacEEBQZ",
        "outputId": "2b10256b-397a-43a0-9f78-d6a0e1bee9c7"
      },
      "source": [
        "print(len(submissions_df))\n",
        "print(len(comments_df))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "807\n",
            "11954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obnFxRpRzlvW"
      },
      "source": [
        "### Simple text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apDuAD0hznjP"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # No lowercasing since upper-case words will indicate sentiment (anger or joy)\n",
        "    # Also no punctuation removal since ! and ? can indicate sentiment\n",
        "\n",
        "    # Whitespace removal\n",
        "    whitespace = '''\\n\\t'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in whitespace:\n",
        "            sentence = sentence.replace(ch, \" \")\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLThuJElzwyj"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "NWq4j_Wx0C2F",
        "outputId": "ae749e07-5431-4b84-942d-a49fcb84facc"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Republicans now 'shocked, shocked' that there'...</td>\n",
              "      <td>© Greg Nash Republicans now 'shocked, shocked'...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Georgia certifies election results confirming ...</td>\n",
              "      <td>Georgia Secretary of State Ben Raffensperger h...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Report: QAnon Congresswoman Was Live-Tweeting ...</td>\n",
              "      <td>Domestic Terrorist: Rep. Lauren Boebert, a new...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>More than 175 current, former law enforcement ...</td>\n",
              "      <td>EXCLUSIVE: More than 175 current and former la...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>GOP group launches billboards demanding Cruz a...</td>\n",
              "      <td>GOP campaigners have called on senators Ted Cr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Study Shows 5.4 Million Have Lost Insurance Am...</td>\n",
              "      <td>Amid the worst public health crisis in a centu...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie — also known as Mr. The Struggle Continues</td>\n",
              "      <td>We use cookies on our websites for a number of...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Medicare for All backers won in safe Democrati...</td>\n",
              "      <td>The votes were still coming in when the Democr...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie Sanders Says Country Must Get Ready for...</td>\n",
              "      <td>Bernie Sanders is sounding the alarm. The Verm...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>Bernie was one of only three Senators to vote ...</td>\n",
              "      <td>Last night an amendment to keep the U.S. embas...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>807 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    submission id  ...  bias\n",
              "0          l6a0q7  ...  left\n",
              "1          jxxs8b  ...  left\n",
              "2          kuscob  ...  left\n",
              "3          j2lufw  ...  left\n",
              "4          l8m3a8  ...  left\n",
              "..            ...  ...   ...\n",
              "802        hr3aiz  ...  left\n",
              "803        lz7cve  ...  left\n",
              "804        jvx3os  ...  left\n",
              "805        indmby  ...  left\n",
              "806        le1obs  ...  left\n",
              "\n",
              "[807 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "is04mZWN0Dh4",
        "outputId": "847a6061-36c6-479a-c041-8e4392cd9440"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>Hey Republican geniuses, I'll bet you were als...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The deficit exploded after the republican tax ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>The Republican Party is a fucking cancer on ou...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>I wish I had gold to give you, just for the ti...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>it's not these politicians that really bug me,...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11949</th>\n",
              "      <td>gsiuc22</td>\n",
              "      <td>mekrf9</td>\n",
              "      <td>conservative</td>\n",
              "      <td>That's actuality a pretty solid point, in isol...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>ggraob5</td>\n",
              "      <td>kiif8x</td>\n",
              "      <td>conservative</td>\n",
              "      <td>Wait till you bring up the science of economic...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>g3v6whd</td>\n",
              "      <td>ilq9tr</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>Dr jo Jorgensen actually said at her okc ok ra...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11952</th>\n",
              "      <td>gey9e3l</td>\n",
              "      <td>k8grel</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>Why would the voting only be rigged in places ...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11953</th>\n",
              "      <td>g6z7f6z</td>\n",
              "      <td>j1dd2u</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>Same here.</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11954 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      comment id  ...   bias\n",
              "0        gkzccbm  ...   left\n",
              "1        gkzg91o  ...   left\n",
              "2        gkzfown  ...   left\n",
              "3        gkz73xz  ...   left\n",
              "4        gkzhm11  ...   left\n",
              "...          ...  ...    ...\n",
              "11949    gsiuc22  ...  right\n",
              "11950    ggraob5  ...  right\n",
              "11951    g3v6whd  ...  right\n",
              "11952    gey9e3l  ...  right\n",
              "11953    g6z7f6z  ...  right\n",
              "\n",
              "[11954 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIKNDOw1z1dh"
      },
      "source": [
        "### Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdUAW0kN9jFi"
      },
      "source": [
        "subreddits = [\n",
        "    'liberal',\n",
        "    'democrats',\n",
        "    'conservative',\n",
        "    'republican',\n",
        "    'obama',\n",
        "    'hillaryclinton',\n",
        "    'shitliberalssay',\n",
        "    'libertarian',\n",
        "    'sandersforpresident'\n",
        "]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5MaUvzq9ud_"
      },
      "source": [
        "# We will store only the compound (overall) sentiment\n",
        "\n",
        "results = {}\n",
        "\n",
        "for subreddit in subreddits:\n",
        "    results[subreddit] = {}\n",
        "    results[subreddit]['article headlines'] = []\n",
        "    results[subreddit]['article bodies'] = []\n",
        "    results[subreddit]['comment bodies'] = []"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZmHQjnXNwwH"
      },
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    headline = row['article headline']\n",
        "    body = row['article body']\n",
        "    results[subreddit]['article headlines'].append(sia.polarity_scores(headline)['compound'])\n",
        "    results[subreddit]['article bodies'].append(sia.polarity_scores(body)['compound'])\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    subreddit = row['subreddit']\n",
        "    comment = row['comment body']\n",
        "    results[subreddit]['comment bodies'].append(sia.polarity_scores(comment)['compound'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGTvQnyb_QAP",
        "outputId": "65f05f5a-c467-4895-d463-54d979e39e42"
      },
      "source": [
        "for subreddit in subreddits:\n",
        "    print(subreddit)\n",
        "    headline_sentiments = results[subreddit]['article headlines']\n",
        "    article_body_sentiments = results[subreddit]['article bodies']\n",
        "    comment_sentiments = results[subreddit]['comment bodies']\n",
        "    print(f\"Headline sentiment: {sum(headline_sentiments) / len(headline_sentiments)}\")\n",
        "    print(f\"Article body sentiment: {sum(article_body_sentiments) / len(article_body_sentiments)}\")\n",
        "    print(f\"Comment sentiment: {sum(comment_sentiments) / len(comment_sentiments)}\")\n",
        "    print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "liberal\n",
            "Headline sentiment: -0.12600352941176465\n",
            "Article body sentiment: -0.04648666666666667\n",
            "Comment sentiment: -0.06488906518010307\n",
            "\n",
            "democrats\n",
            "Headline sentiment: -0.12061851851851853\n",
            "Article body sentiment: 0.3994111111111111\n",
            "Comment sentiment: 0.03578343653250772\n",
            "\n",
            "conservative\n",
            "Headline sentiment: -0.06153121019108282\n",
            "Article body sentiment: -0.011707643312101897\n",
            "Comment sentiment: 0.031566909090909055\n",
            "\n",
            "republican\n",
            "Headline sentiment: 0.002089189189189178\n",
            "Article body sentiment: 0.1820243243243243\n",
            "Comment sentiment: 0.026116666666666663\n",
            "\n",
            "obama\n",
            "Headline sentiment: 0.060933333333333325\n",
            "Article body sentiment: 0.4760060606060606\n",
            "Comment sentiment: 0.2396809523809524\n",
            "\n",
            "hillaryclinton\n",
            "Headline sentiment: -0.0037677966101694943\n",
            "Article body sentiment: 0.5367000000000001\n",
            "Comment sentiment: 0.036123958333333324\n",
            "\n",
            "shitliberalssay\n",
            "Headline sentiment: -0.41447500000000004\n",
            "Article body sentiment: -0.33492500000000003\n",
            "Comment sentiment: -0.03090666666666666\n",
            "\n",
            "libertarian\n",
            "Headline sentiment: -0.09687157894736843\n",
            "Article body sentiment: -0.03523842105263156\n",
            "Comment sentiment: -0.03804564867042713\n",
            "\n",
            "sandersforpresident\n",
            "Headline sentiment: 0.050557777777777764\n",
            "Article body sentiment: 0.2410622222222222\n",
            "Comment sentiment: 0.08994886075949364\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yCY8lX1NrGy"
      },
      "source": [
        "### Further preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUm1l8L6R2o_"
      },
      "source": [
        "Now we perform further text preprocessing before vocab analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5igJsQRz7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324423bb-1802-4135-9221-30b10c873450"
      },
      "source": [
        "# Text preprocessing preparation\n",
        "\n",
        "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:          \n",
        "        return None\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# required for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# required for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zeni9Z_1NwbL"
      },
      "source": [
        "def preprocess(sentence):\n",
        "\n",
        "    # Lowercase\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # Punctuation removal\n",
        "    punctuations = '''!()-—[]{};:'\"“”‘’\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "    for ch in sentence: \n",
        "        if ch in punctuations: \n",
        "            sentence = sentence.replace(ch, \"\")\n",
        "\n",
        "    # Stop word removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    remaining_words = [word for word in sentence.split() if not word in stop_words]\n",
        "\n",
        "    sentence = \" \".join(remaining_words)\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatized_words = []\n",
        "\n",
        "    # In order to lemmatise we must first POS-tag each sentence\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "    for word, tag in tagged:\n",
        "        pos = nltk_tag_to_wordnet_tag(tag) \n",
        "        if pos is not None:\n",
        "            word = lemmatizer.lemmatize(word, pos=pos)\n",
        "\n",
        "        lemmatized_words.append(word)\n",
        "\n",
        "    sentence = \" \".join(lemmatized_words)\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avRNm30BS7eM"
      },
      "source": [
        "submissions_df['article headline'] = submissions_df['article headline'].apply(preprocess)\n",
        "submissions_df['article body'] = submissions_df['article body'].apply(preprocess)\n",
        "comments_df['comment body'] = comments_df['comment body'].apply(preprocess)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu2eTdaSTFHt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "093e5b2d-704b-48f1-c4db-b55646ee78d3"
      },
      "source": [
        "submissions_df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>article headline</th>\n",
              "      <th>article body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican shock shocked there deficit hahahah...</td>\n",
              "      <td>© greg nash republican shock shocked there def...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jxxs8b</td>\n",
              "      <td>liberal</td>\n",
              "      <td>georgia certifies election result confirm bide...</td>\n",
              "      <td>georgia secretary state ben raffensperger hold...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kuscob</td>\n",
              "      <td>liberal</td>\n",
              "      <td>report qanon congresswoman livetweeting nancy ...</td>\n",
              "      <td>domestic terrorist rep lauren boebert newly el...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>j2lufw</td>\n",
              "      <td>liberal</td>\n",
              "      <td>175 current former law enforcement official en...</td>\n",
              "      <td>exclusive 175 current former law enforcement o...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l8m3a8</td>\n",
              "      <td>liberal</td>\n",
              "      <td>gop group launch billboard demand cruz hawley ...</td>\n",
              "      <td>gop campaigner call senator ted cruz josh hawl...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>hr3aiz</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>study show 54 million lose insurance amid pand...</td>\n",
              "      <td>amid bad public health crisis century devastat...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>lz7cve</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie also know mr struggle continue</td>\n",
              "      <td>use cooky websites number purpose include anal...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>804</th>\n",
              "      <td>jvx3os</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>medicare backer safe democratic district trump...</td>\n",
              "      <td>vote still come democratic establishment set n...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>indmby</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie sander say country must get ready trump...</td>\n",
              "      <td>bernie sander sound alarm vermont senator warn...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>le1obs</td>\n",
              "      <td>sandersforpresident</td>\n",
              "      <td>bernie one three senator vote keep us embassy ...</td>\n",
              "      <td>last night amendment keep us embassy jerusalem...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>807 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    submission id  ...  bias\n",
              "0          l6a0q7  ...  left\n",
              "1          jxxs8b  ...  left\n",
              "2          kuscob  ...  left\n",
              "3          j2lufw  ...  left\n",
              "4          l8m3a8  ...  left\n",
              "..            ...  ...   ...\n",
              "802        hr3aiz  ...  left\n",
              "803        lz7cve  ...  left\n",
              "804        jvx3os  ...  left\n",
              "805        indmby  ...  left\n",
              "806        le1obs  ...  left\n",
              "\n",
              "[807 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhz2MTlDTHNV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "956c50fa-2ea6-43eb-bb15-6c840873e431"
      },
      "source": [
        "comments_df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment id</th>\n",
              "      <th>submission id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>comment body</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gkzccbm</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>hey republican genius ill bet also unaware tru...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gkzg91o</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>deficit explode republican tax cut single one ...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gkzfown</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>republican party fuck cancer country need finish</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gkz73xz</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>wish gold give title alone</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gkzhm11</td>\n",
              "      <td>l6a0q7</td>\n",
              "      <td>liberal</td>\n",
              "      <td>politician really bug reaction predictable foo...</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11949</th>\n",
              "      <td>gsiuc22</td>\n",
              "      <td>mekrf9</td>\n",
              "      <td>conservative</td>\n",
              "      <td>thats actuality pretty solid point isolation r...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11950</th>\n",
              "      <td>ggraob5</td>\n",
              "      <td>kiif8x</td>\n",
              "      <td>conservative</td>\n",
              "      <td>wait till bring science economics type suddenl...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11951</th>\n",
              "      <td>g3v6whd</td>\n",
              "      <td>ilq9tr</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>dr jo jorgensen actually say okc ok rally want...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11952</th>\n",
              "      <td>gey9e3l</td>\n",
              "      <td>k8grel</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>would vote rigged place trump lose hypocrite s...</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11953</th>\n",
              "      <td>g6z7f6z</td>\n",
              "      <td>j1dd2u</td>\n",
              "      <td>libertarian</td>\n",
              "      <td></td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11954 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      comment id  ...   bias\n",
              "0        gkzccbm  ...   left\n",
              "1        gkzg91o  ...   left\n",
              "2        gkzfown  ...   left\n",
              "3        gkz73xz  ...   left\n",
              "4        gkzhm11  ...   left\n",
              "...          ...  ...    ...\n",
              "11949    gsiuc22  ...  right\n",
              "11950    ggraob5  ...  right\n",
              "11951    g3v6whd  ...  right\n",
              "11952    gey9e3l  ...  right\n",
              "11953    g6z7f6z  ...  right\n",
              "\n",
              "[11954 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXujLRcM_3W"
      },
      "source": [
        "### Vocab overlap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xDSDEBNAt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97774faa-7e70-4ae6-d918-8d8ebb033d3e"
      },
      "source": [
        "article_headline_vocab = []\n",
        "article_body_vocab = []\n",
        "comment_vocab = []\n",
        "\n",
        "for i, row in submissions_df.iterrows():\n",
        "    article_headline = row['article headline']\n",
        "    article_body = row['article body']\n",
        "    for word in article_headline.split():\n",
        "        article_headline_vocab.append(word)\n",
        "    for word in article_body.split():\n",
        "        article_body_vocab.append(word)\n",
        "\n",
        "for i, row in comments_df.iterrows():\n",
        "    comment_body = row['comment body']\n",
        "    for word in comment_body.split():\n",
        "        comment_vocab.append(word)\n",
        "\n",
        "print(len(article_headline_vocab))\n",
        "print(len(article_body_vocab))\n",
        "print(len(comment_vocab))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8823\n",
            "276006\n",
            "211725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYTHcILBNmdr"
      },
      "source": [
        "article_headline_multiset = Counter(article_headline_vocab)\n",
        "article_body_multiset = Counter(article_body_vocab)\n",
        "comment_multiset = Counter(comment_vocab)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AINbnyPRe3rQ",
        "outputId": "4099ecdb-20d4-4aa3-b201-d937dea4a1cc"
      },
      "source": [
        "# Computing Jaccard distances\n",
        "\n",
        "headline_body_intersect = list((article_headline_multiset & article_body_multiset).elements())\n",
        "headline_comment_intersect = list((article_headline_multiset & comment_multiset).elements())\n",
        "body_comment_intersect = list((article_body_multiset & comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_intersect))\n",
        "print(len(headline_comment_intersect))\n",
        "print(len(body_comment_intersect))\n",
        "\n",
        "headline_body_union = list((article_headline_multiset | article_body_multiset).elements())\n",
        "headline_comment_union = list((article_headline_multiset | comment_multiset).elements())\n",
        "body_comment_union = list((article_body_multiset | comment_multiset).elements())\n",
        "\n",
        "print(len(headline_body_union))\n",
        "print(len(headline_comment_union))\n",
        "print(len(body_comment_union))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8606\n",
            "8325\n",
            "144718\n",
            "276223\n",
            "212223\n",
            "343013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zahTnTbIfeiQ",
        "outputId": "f9848a33-8d11-4f95-e940-763690c2263c"
      },
      "source": [
        "headline_body_jaccard = len(headline_body_intersect) / len(headline_body_union)\n",
        "headline_comment_jaccard = len(headline_comment_intersect) / len(headline_comment_union)\n",
        "body_comment_jaccard = len(body_comment_intersect) / len(body_comment_union)\n",
        "\n",
        "print(f\"Headline & article body Jaccard distance: {headline_body_jaccard}\")\n",
        "print(f\"Headline and comment body Jaccard distance: {headline_comment_jaccard}\")\n",
        "print(f\"Article body and comment body Jaccard distance: {body_comment_jaccard}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headline & article body Jaccard distance: 0.031155986286442477\n",
            "Headline and comment body Jaccard distance: 0.039227604925008125\n",
            "Article body and comment body Jaccard distance: 0.42190237687784427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fSOH0Z40SHv"
      },
      "source": [
        "### Save data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDT0SflI0TIS"
      },
      "source": [
        "submissions_df.to_csv('submissions_preprocessed.tsv', sep='\\t', index=False)\n",
        "comments_df.to_csv('comments_preprocessed.tsv', sep='\\t', index=False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x6_IIL00kLf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}